{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sciencedaily.com/releases/2022/02/220225233722.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233723.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233724.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233726.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233727.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233728.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233729.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233730.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233731.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233733.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233734.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233735.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233736.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233737.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233738.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233740.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233741.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233742.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233743.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233744.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233746.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233747.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233748.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233749.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233750.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233752.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233753.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233754.htm\n",
      "https://www.sciencedaily.com/releases/2022/02/220225233755.htm\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "from pytz import timezone\n",
    "from time import time, sleep\n",
    "\n",
    "\n",
    "def insert(l):\n",
    "    url = l\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req,timeout=10).read()\n",
    "    from datetime import datetime\n",
    "\n",
    "    # current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    timestamp = datetime.timestamp(now)\n",
    "    print(\"timestamp =\", timestamp)\n",
    "    dt_object = datetime.fromtimestamp(timestamp)\n",
    "\n",
    "    print(\"dt_object =\", dt_object)\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(webpage)\n",
    "    para = \" \"\n",
    "    term = \" \"\n",
    "    title = soup.find(id=\"headline\").string\n",
    "    slug = title.replace(\" \", \"-\").lower()\n",
    "    subtitle = soup.find(id='subtitle')\n",
    "    paragraph = soup.find(id=\"story_text\").find_all('p')[:-4]\n",
    "    for a in paragraph:\n",
    "        para = para + str(a)\n",
    "    source =  soup.find(id=\"source\").string\n",
    "    summary = soup.find(id=\"abstract\").string\n",
    "    journal = soup.find(id=\"journal_references\").find('li')\n",
    "    terms = soup.find(id=\"related_terms\").find_all('a')\n",
    "    for a in terms:\n",
    "        term = term + a.string + \",\"\n",
    "    MainCat = soup.find(id=\"related_topics\").find_all('a')[0]\n",
    "    Cat = soup.find(id=\"related_topics\").find_all('a')[1]\n",
    "    query = \"\"\"INSERT INTO news_news ( title, slug, updated_on, content, created_on, image, status, source, summary, author_id, category_id, journal_reference) VALUES (%s, %s, %s ,%s, %s ,'uploads/news/logo.jpg',1, %s, %s,1, 27, %s ) \"\"\"\n",
    "    print(\"Title\" + title)\n",
    "    print(\"Tags \" + term)\n",
    "    print(\"Main Category  \" + str(MainCat.string))\n",
    "    print(\"Category \" + str(Cat.string))\n",
    "\n",
    "    import mysql.connector\n",
    "    from mysql.connector import Error\n",
    "\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='database-1.cez5x0venctn.ap-south-1.rds.amazonaws.com',\n",
    "                                             database='MAYUR',\n",
    "                                             user='admin',\n",
    "                                             password='qwertyuiop')\n",
    "        if connection.is_connected():\n",
    "            db_Info = connection.get_server_info()\n",
    "            print(\"Connected to MySQL Server version \", db_Info)\n",
    "            cursor = connection.cursor(prepared=True)\n",
    "            cursor.execute(\"select database();\")\n",
    "            record = cursor.fetchone()\n",
    "            print(\"You're connected to database: \", record)\n",
    "            tuple1 = (title, slug, dt_object, str(para),dt_object, source, summary, str(journal))\n",
    "            cursor.execute(query, tuple1)\n",
    "            connection.commit()\n",
    "            print(cursor.rowcount, \"Record inserted successfully into news table\")\n",
    "\n",
    "    except Error as e:\n",
    "        print(\"Error while connecting to MySQL\", e)\n",
    "        \n",
    "def donathing():\n",
    "    return 0\n",
    "        \n",
    "\n",
    "while(True):\n",
    "    sleep(.5)\n",
    "    tz = timezone('EST')\n",
    "    now = dt.now(tz) - timedelta(hours=26, minutes=35)\n",
    "    s = now.strftime(\"%y %m %d %H %M %S\")\n",
    "    year = now.strftime(\"%y\")\n",
    "    month = now.strftime(\"%m\")\n",
    "    link = s.replace(\" \", \"\")\n",
    "    url = \"https://www.sciencedaily.com/releases/20\"+year+\"/\"+month+\"/\"+link+\".htm\"\n",
    "    try:\n",
    "        req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urlopen(req,timeout=10).read()\n",
    "        print(\"Link Make\")\n",
    "        print(url)\n",
    "        insert(url)\n",
    "        print('\\nExample 1:', s)\n",
    "    except:\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
